{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from PIL import Image   #  pip install pillow\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_path = glob.glob('/home/bear/dl/data/dataset2/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/bear/dl/data/dataset2/cloudy60.jpg',\n",
       " '/home/bear/dl/data/dataset2/rain184.jpg',\n",
       " '/home/bear/dl/data/dataset2/sunrise242.jpg',\n",
       " '/home/bear/dl/data/dataset2/rain189.jpg',\n",
       " '/home/bear/dl/data/dataset2/rain143.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_imgs_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dataset = Mydataset(all_imgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bear/dl/data/dataset2/sunrise356.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_dataset[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wh_dl = torch.utils.data.DataLoader(weather_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/bear/dl/data/dataset2/cloudy60.jpg',\n",
       " '/home/bear/dl/data/dataset2/rain184.jpg',\n",
       " '/home/bear/dl/data/dataset2/sunrise242.jpg',\n",
       " '/home/bear/dl/data/dataset2/rain189.jpg']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(wh_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['cloudy', 'rain', 'shine', 'sunrise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_to_idx = dict((c, i) for i, c in enumerate(species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cloudy': 0, 'rain': 1, 'shine': 2, 'sunrise': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_species = dict((k, v) for v, k in species_to_idx.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx_to_species' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m idx_to_species[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'idx_to_species' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "\n",
    "for img in all_imgs_path:\n",
    "    for i, c in enumerate(species):\n",
    "        if c in img:\n",
    "            all_labels.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 3, 1, 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.Resize((96, 96)),\n",
    "                    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(data.Dataset):\n",
    "    def __init__(self, img_paths, labels, transform):\n",
    "        self.imgs = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        pil_img = Image.open(img)\n",
    "        pil_img = pil_img.convert(\"RGB\")    # 可选,建议都使用\n",
    "        data = self.transforms(pil_img)\n",
    "        \n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dataset = Mydataset(all_imgs_path, all_labels, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Mydataset"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weather_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_dl = data.DataLoader(\n",
    "                            weather_dataset,\n",
    "                            batch_size=16,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_batch, labels_batch = next(iter(weather_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 96, 96])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.permutation(len(all_imgs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 285,  250,  529, ..., 1053,  719,  522])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_path = np.array(all_imgs_path)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = np.array(all_labels)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = int(len(all_imgs_path)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = all_imgs_path[:s]\n",
    "train_labels = all_labels[:s]\n",
    "test_imgs = all_imgs_path[s:]\n",
    "test_labels = all_labels[s:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Mydataset(train_imgs, train_labels, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = Mydataset(test_imgs, test_labels, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = data.DataLoader(train_ds,\n",
    "                           batch_size=16,\n",
    "                           shuffle=True)\n",
    "test_dl = data.DataLoader(test_ds,\n",
    "                           batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, labels = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 96, 96])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class New_dataset(data.Dataset):\n",
    "    def __init__(self, some_dataset):\n",
    "        self.ds = some_dataset\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.ds[index]\n",
    "        img = img.permute(1,2,0)\n",
    "        return img, label\n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_dataset = New_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_new_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = r'/home/bear/dl/data/dataset/animals'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset =  torchvision.datasets.ImageFolder(\n",
    "        img_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['elephant', 'giraffe', 'lion', 'monkey', 'tiger']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elephant': 0, 'giraffe': 1, 'lion': 2, 'monkey': 3, 'tiger': 4}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1955"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = int(0.8*count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1564"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = count - train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = data.random_split(dataset, [train_count, test_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=train_dataset.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class New_dataset(data.Dataset):\n",
    "    def __init__(self, some_dataset,transform):\n",
    "        self.transforms = transform\n",
    "        self.ds = some_dataset\n",
    "    def __getitem__(self, index):\n",
    "        img, label = self.ds[index]\n",
    "        data = self.transforms(img)\n",
    "        return data, label\n",
    "    def __len__(self):\n",
    "        return len(self.ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_dataset = New_dataset(train_dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_new_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7569, 0.7804, 0.8078,  ..., 0.7765, 0.7765, 0.7804],\n",
       "         [0.7647, 0.7882, 0.8196,  ..., 0.7765, 0.7765, 0.7804],\n",
       "         [0.7569, 0.7843, 0.8196,  ..., 0.7765, 0.7765, 0.7804],\n",
       "         ...,\n",
       "         [0.8275, 0.7725, 0.7608,  ..., 0.3451, 0.3294, 0.3255],\n",
       "         [0.8314, 0.7765, 0.7294,  ..., 0.3333, 0.3255, 0.3490],\n",
       "         [0.8039, 0.7647, 0.7059,  ..., 0.3216, 0.3216, 0.3333]],\n",
       "\n",
       "        [[0.8314, 0.8510, 0.8706,  ..., 0.8471, 0.8471, 0.8510],\n",
       "         [0.8471, 0.8627, 0.8863,  ..., 0.8471, 0.8471, 0.8510],\n",
       "         [0.8549, 0.8706, 0.8902,  ..., 0.8471, 0.8471, 0.8510],\n",
       "         ...,\n",
       "         [0.7216, 0.6667, 0.6549,  ..., 0.3294, 0.3137, 0.3098],\n",
       "         [0.7255, 0.6706, 0.6235,  ..., 0.3176, 0.3098, 0.3333],\n",
       "         [0.6980, 0.6588, 0.6000,  ..., 0.3059, 0.3059, 0.3176]],\n",
       "\n",
       "        [[0.8588, 0.8784, 0.8980,  ..., 0.8627, 0.8627, 0.8667],\n",
       "         [0.8745, 0.8941, 0.9137,  ..., 0.8627, 0.8627, 0.8667],\n",
       "         [0.8863, 0.9020, 0.9216,  ..., 0.8627, 0.8627, 0.8667],\n",
       "         ...,\n",
       "         [0.6039, 0.5490, 0.5373,  ..., 0.2863, 0.2706, 0.2706],\n",
       "         [0.6078, 0.5529, 0.5059,  ..., 0.2745, 0.2667, 0.2941],\n",
       "         [0.5804, 0.5412, 0.4824,  ..., 0.2627, 0.2667, 0.2784]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img = Image.open('/home/bear/dl/data/dataset/animals/elephant/pic_081.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Image.show of <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=276x183 at 0x7F4C69F8AE50>>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pil_img.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
