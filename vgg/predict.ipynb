{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data\n",
    "import time\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import logging\n",
    "import torchvision.models as models\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, CosineAnnealingWarmRestarts,StepLR, OneCycleLR\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu',index= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    model = torchvision.models.vgg16(pretrained=True)\n",
    "    model.classifier[-1].out_features = 5\n",
    "    model = model.to(device)\n",
    "    output = model(image)\n",
    "    \n",
    "    ret_val, predicted = torch.max(output, 1)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_path = glob.glob(r'/home/bear/dl/data/dataset/animal_test/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = ['elephant', 'giraffe', 'lion', 'monkey', 'tiger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'elephant', 1: 'giraffe', 2: 'lion', 3: 'monkey', 4: 'tiger'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_species = dict((v,k) for v, k in enumerate(species))\n",
    "idx_to_species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize([224,224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition():\n",
    "    print(\"begin to recogition\")\n",
    "    for img in all_imgs_path:\n",
    "        for spec in species:\n",
    "            if spec in img:\n",
    "                test_img = Image.open(img)\n",
    "                trans_img = trans(test_img).unsqueeze(0)\n",
    "                input_img = trans_img.to(device)\n",
    "                result = predict(input_img)\n",
    "                result = result.item()\n",
    "                print(\"real: \"+spec + \"  \"+ \"Predict: \"+idx_to_species[result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin to recogition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real: lion  Predict: lion\n",
      "real: tiger  Predict: tiger\n",
      "real: lion  Predict: lion\n",
      "real: elephant  Predict: elephant\n",
      "real: monkey  Predict: monkey\n",
      "real: tiger  Predict: tiger\n",
      "real: monkey  Predict: monkey\n",
      "real: giraffe  Predict: giraffe\n",
      "real: giraffe  Predict: giraffe\n",
      "real: elephant  Predict: elephant\n"
     ]
    }
   ],
   "source": [
    "recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
